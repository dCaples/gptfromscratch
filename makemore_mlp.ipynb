{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, '.': 0}\n",
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "\n",
    "print(stoi)\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multilayer perceptron \n",
    "given any consecutive 3 letters of a name, what is the next letter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... ---> e\n",
      "..e ---> m\n",
      ".em ---> m\n",
      "emm ---> a\n",
      "mma ---> .\n",
      "olivia\n",
      "... ---> o\n",
      "..o ---> l\n",
      ".ol ---> i\n",
      "oli ---> v\n",
      "liv ---> i\n",
      "ivi ---> a\n",
      "via ---> .\n",
      "ava\n",
      "... ---> a\n",
      "..a ---> v\n",
      ".av ---> a\n",
      "ava ---> .\n",
      "isabella\n",
      "... ---> i\n",
      "..i ---> s\n",
      ".is ---> a\n",
      "isa ---> b\n",
      "sab ---> e\n",
      "abe ---> l\n",
      "bel ---> l\n",
      "ell ---> a\n",
      "lla ---> .\n",
      "sophia\n",
      "... ---> s\n",
      "..s ---> o\n",
      ".so ---> p\n",
      "sop ---> h\n",
      "oph ---> i\n",
      "phi ---> a\n",
      "hia ---> .\n"
     ]
    }
   ],
   "source": [
    "block_size = 3 # context length\n",
    "X, Y = [], []\n",
    "\n",
    "for w in words[:5]:\n",
    "    print(w)\n",
    "    context = [0] * block_size # [0,0,0]\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        Y.append(ix)\n",
    "        X.append(context)\n",
    "        print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0],\n",
       "        [ 0,  0,  5],\n",
       "        [ 0,  5, 13],\n",
       "        [ 5, 13, 13],\n",
       "        [13, 13,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 15],\n",
       "        [ 0, 15, 12],\n",
       "        [15, 12,  9],\n",
       "        [12,  9, 22],\n",
       "        [ 9, 22,  9],\n",
       "        [22,  9,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  1],\n",
       "        [ 0,  1, 22],\n",
       "        [ 1, 22,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  9],\n",
       "        [ 0,  9, 19],\n",
       "        [ 9, 19,  1],\n",
       "        [19,  1,  2],\n",
       "        [ 1,  2,  5],\n",
       "        [ 2,  5, 12],\n",
       "        [ 5, 12, 12],\n",
       "        [12, 12,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 19],\n",
       "        [ 0, 19, 15],\n",
       "        [19, 15, 16],\n",
       "        [15, 16,  8],\n",
       "        [16,  8,  9],\n",
       "        [ 8,  9,  1]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
       "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.int64, torch.Size([32]), torch.int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X.dtype, Y.shape, Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.6297, -1.0404])\n",
      "tensor([1.7370, 0.2847])\n",
      "tensor([[ 0.6297, -1.0404],\n",
      "        [ 1.7370,  0.2847]])\n"
     ]
    }
   ],
   "source": [
    "embed_dims = 2\n",
    "\n",
    "\n",
    "# embed into a lower-dimensional space\n",
    "C = torch.randn(27, embed_dims)\n",
    "\n",
    "print(C[1])\n",
    "print(C[2])\n",
    "\n",
    "print(C[[1,2]]) # we can index multiple slices using a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 1]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.7370,  0.2847],\n",
       "         [ 0.6297, -1.0404]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = torch.zeros(1,2, dtype=int)\n",
    "index[0][1] = 1\n",
    "index[0][0] = 2\n",
    "print(index)\n",
    "# we can also so multidimensional slices\n",
    "C[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# actually convert the words into their embeddings\n",
    "C[X].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[13, 2] # middle number-for-char of 13th word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.6297, -1.0404])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[X][13,2] # get the token for the middle caracter of the 13th word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.6297, -1.0404])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify\n",
    "C[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have data in the form [token], [token], [token]\n",
    "# where token is [number, number, number]\n",
    "W1 = torch.randn((6, 100))\n",
    "b1 = torch.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6738, -0.3726,  0.6738, -0.3726,  0.6738, -0.3726],\n",
       "        [ 0.6738, -0.3726,  0.6738, -0.3726, -0.1064,  0.4087],\n",
       "        [ 0.6738, -0.3726, -0.1064,  0.4087,  0.9086, -0.0898],\n",
       "        [-0.1064,  0.4087,  0.9086, -0.0898,  0.9086, -0.0898],\n",
       "        [ 0.9086, -0.0898,  0.9086, -0.0898,  0.6297, -1.0404],\n",
       "        [ 0.6738, -0.3726,  0.6738, -0.3726,  0.6738, -0.3726],\n",
       "        [ 0.6738, -0.3726,  0.6738, -0.3726, -0.4256, -0.3790],\n",
       "        [ 0.6738, -0.3726, -0.4256, -0.3790, -0.0641,  1.2197],\n",
       "        [-0.4256, -0.3790, -0.0641,  1.2197, -0.0178, -0.4567],\n",
       "        [-0.0641,  1.2197, -0.0178, -0.4567, -1.0276, -2.2616],\n",
       "        [-0.0178, -0.4567, -1.0276, -2.2616, -0.0178, -0.4567],\n",
       "        [-1.0276, -2.2616, -0.0178, -0.4567,  0.6297, -1.0404],\n",
       "        [ 0.6738, -0.3726,  0.6738, -0.3726,  0.6738, -0.3726],\n",
       "        [ 0.6738, -0.3726,  0.6738, -0.3726,  0.6297, -1.0404],\n",
       "        [ 0.6738, -0.3726,  0.6297, -1.0404, -1.0276, -2.2616],\n",
       "        [ 0.6297, -1.0404, -1.0276, -2.2616,  0.6297, -1.0404],\n",
       "        [ 0.6738, -0.3726,  0.6738, -0.3726,  0.6738, -0.3726],\n",
       "        [ 0.6738, -0.3726,  0.6738, -0.3726, -0.0178, -0.4567],\n",
       "        [ 0.6738, -0.3726, -0.0178, -0.4567,  1.1173, -0.4146],\n",
       "        [-0.0178, -0.4567,  1.1173, -0.4146,  0.6297, -1.0404],\n",
       "        [ 1.1173, -0.4146,  0.6297, -1.0404,  1.7370,  0.2847],\n",
       "        [ 0.6297, -1.0404,  1.7370,  0.2847, -0.1064,  0.4087],\n",
       "        [ 1.7370,  0.2847, -0.1064,  0.4087, -0.0641,  1.2197],\n",
       "        [-0.1064,  0.4087, -0.0641,  1.2197, -0.0641,  1.2197],\n",
       "        [-0.0641,  1.2197, -0.0641,  1.2197,  0.6297, -1.0404],\n",
       "        [ 0.6738, -0.3726,  0.6738, -0.3726,  0.6738, -0.3726],\n",
       "        [ 0.6738, -0.3726,  0.6738, -0.3726,  1.1173, -0.4146],\n",
       "        [ 0.6738, -0.3726,  1.1173, -0.4146, -0.4256, -0.3790],\n",
       "        [ 1.1173, -0.4146, -0.4256, -0.3790, -0.1746, -0.9269],\n",
       "        [-0.4256, -0.3790, -0.1746, -0.9269,  0.2020,  0.7138],\n",
       "        [-0.1746, -0.9269,  0.2020,  0.7138, -0.0178, -0.4567],\n",
       "        [ 0.2020,  0.7138, -0.0178, -0.4567,  0.6297, -1.0404]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inefficient flatten method\n",
    "# flatten the three tokens [A,B, C] into [a,a,b,b,c,c]\n",
    "# current structure:[  (dim1-column)\n",
    "# [[aa],[bb],[cc]]\n",
    "# [[aa],[bb],[cc]]\n",
    "# ...\n",
    "# [[aa],[bb],[cc]]\n",
    "#]\n",
    "# Goal:[\n",
    "# [aabbcc]\n",
    "# [aabbcc]\n",
    "# ...\n",
    "# [aabbcc]\n",
    "#]\n",
    "\n",
    "# achieve by: for each element in dim1, concatenate\n",
    "# ie concat along dim2\n",
    "# end shape: (32,6)\n",
    "\n",
    "torch.unbind(emb, 1)\n",
    "# this returns data in the format:\n",
    "# (\n",
    "# [[aa], [aa], [aa], ..., [aa]] -> this dimension is which word\n",
    "# [[bb], [bb], [bb], ..., [bb]] -> this dimension is which word\n",
    "# [[cc], [cc], [cc], ..., [cc]] -> this dimension is which word\n",
    "# )\n",
    "\n",
    "# now we need to call cat. \n",
    "# if we concatenated along dimension 0 (default), we would just\n",
    "# make something like [[aa][aa]...[bb][bb]...[cc][cc]]\n",
    "# this wouldn't be separated into words.\n",
    "# instead we want to concatenate along dimension 1\n",
    "# so we get a list of [w1[aabbcc], w2[aabbcc],...]\n",
    "torch.cat(torch.unbind(emb, 1), 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1],\n",
       "         [ 2,  3],\n",
       "         [ 4,  5]],\n",
       "\n",
       "        [[ 6,  7],\n",
       "         [ 8,  9],\n",
       "         [10, 11]],\n",
       "\n",
       "        [[12, 13],\n",
       "         [14, 15],\n",
       "         [16, 17]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(18)\n",
    "a # [0,1,2,...]\n",
    "a.view(2,9) # [[0-8], [9-17]]\n",
    "a.view(3,3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g7/gy4f443x1f73j2vf0qnb_74c0000gn/T/ipykernel_96642/1936328721.py:1: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  a.storage() # everythin is a 1d tensor, view just changes how we see it\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " 0\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5\n",
       " 6\n",
       " 7\n",
       " 8\n",
       " 9\n",
       " 10\n",
       " 11\n",
       " 12\n",
       " 13\n",
       " 14\n",
       " 15\n",
       " 16\n",
       " 17\n",
       "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 18]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.storage() # everythin is a 1d tensor, view just changes how we see it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# more efficient way to flatten\n",
    "print(emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# real conv layer\n",
    "W1 = torch.randn((6,100))\n",
    "b1 = torch.randn(100)\n",
    "h = torch.tanh(emb.view(-1,6) @ W1 + b1) #-1 means infer size\n",
    "h.shape # hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = torch.randn((100, 27))\n",
    "b2 = torch.randn(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = (h @ W2 + b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = logits.exp()\n",
    "prob = counts/counts.sum(1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
       "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.7786)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -prob[torch.arange(32), Y].log().mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Respectable :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 3 # context length\n",
    "X, Y = [], []\n",
    "\n",
    "for w in words:\n",
    "    context = [0] * block_size # [0,0,0]\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        Y.append(ix)\n",
    "        X.append(context)\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([228146, 3]), torch.Size([228146]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.randn((27,2)) # letters to embeddings\n",
    "W1 = torch.randn((6, 100))\n",
    "b1 = torch.randn(100)\n",
    "W2 = torch.randn((100, 27))\n",
    "b2 = torch.randn(27)\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3481"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters) # number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lre = torch.linspace(-3, 0, 1000)\n",
    "lrs = 10 ** lre # exponential spacing (idk why)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.410581588745117\n"
     ]
    }
   ],
   "source": [
    "lri =[]\n",
    "lossi = []\n",
    "\n",
    "for i in range(10000):\n",
    "\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0,X.shape[0],(32,)) #32 integers that index into dataset\n",
    "\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[X[ix]] # embed to tokens (32, 3, 2). Only use minibatch\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1) #(32, 100)\n",
    "    logits = h @ W2 + b2 # (32, 27)\n",
    "    loss = F.cross_entropy(logits, Y[ix]) # shortcut for commented code above. Use minibatch added too\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad= None\n",
    "\n",
    "    loss.backward()\n",
    "    # update\n",
    "    lr = 0.01\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "\n",
    "    # track learning rate stats\n",
    "    # lri.append(lr)\n",
    "    # lossi.append(loss.item())\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(lre, lossi)# .1 is a good leaerning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2825822830200195\n"
     ]
    }
   ],
   "source": [
    "\n",
    "emb = C[X] # embed to tokens (32, 3, 2). Only use minibatch\n",
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1) #(32, 100)\n",
    "logits = h @ W2 + b2 # (32, 27)\n",
    "loss = F.cross_entropy(logits, Y) # shortcut for commented code above. Use minibatch added too\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ukskui\n",
      "raaiaaaa\n",
      "ay\n",
      "eriinnnaen\n",
      "\n",
      "kaafrpztqn\n",
      "hayljylei\n",
      "ren\n",
      "byq\n",
      "uomleca\n"
     ]
    }
   ],
   "source": [
    "# now let's generate some names\n",
    "def generate():\n",
    "    context = torch.tensor([0,0,0])\n",
    "    out = []\n",
    "    for _ in range(10):\n",
    "        # get the last 3 characters of the context\n",
    "        contextview = context.view(1,3)\n",
    "        emb = C[context]\n",
    "        h = torch.tanh(emb.view(1, 6) @ W1 + b1)\n",
    "        logits = h @ W2 + b2\n",
    "        prob = F.softmax(logits, 1)\n",
    "        nextchar = torch.multinomial(prob, 1).item()\n",
    "        if nextchar == 0: break\n",
    "        out.append(nextchar)\n",
    "        context = torch.cat([context[1:], torch.tensor([nextchar])])\n",
    "    return ''.join(itos[i] for i in out)\n",
    "\n",
    "\n",
    "for _ in range(10):\n",
    "    print(generate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Scientific Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training split, dev/validation split, test split\n",
    "# 80%, 10%, 10%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... ---> e\n",
      "..e ---> m\n",
      ".em ---> m\n",
      "emm ---> a\n",
      "mma ---> .\n",
      "olivia\n",
      "... ---> o\n",
      "..o ---> l\n",
      ".ol ---> i\n",
      "oli ---> v\n",
      "liv ---> i\n",
      "ivi ---> a\n",
      "via ---> .\n",
      "ava\n",
      "... ---> a\n",
      "..a ---> v\n",
      ".av ---> a\n",
      "ava ---> .\n",
      "isabella\n",
      "... ---> i\n",
      "..i ---> s\n",
      ".is ---> a\n",
      "isa ---> b\n",
      "sab ---> e\n",
      "abe ---> l\n",
      "bel ---> l\n",
      "ell ---> a\n",
      "lla ---> .\n",
      "sophia\n",
      "... ---> s\n",
      "..s ---> o\n",
      ".so ---> p\n",
      "sop ---> h\n",
      "oph ---> i\n",
      "phi ---> a\n",
      "hia ---> .\n"
     ]
    }
   ],
   "source": [
    "block_size = 3 # context length\n",
    "X, Y = [], []\n",
    "\n",
    "for w in words[:5]:\n",
    "    print(w)\n",
    "    context = [0] * block_size # [0,0,0]\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        Y.append(ix)\n",
    "        X.append(context)\n",
    "        print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(words):\n",
    "    block_size = 3 # context length\n",
    "    X, Y = [], []\n",
    "    for w in words:\n",
    "        context = [0] * block_size # [0,0,0]\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            Y.append(ix)\n",
    "            X.append(context)\n",
    "            context = context[1:] + [ix]\n",
    "    return torch.tensor(X), torch.tensor(Y)\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8 * len(words))\n",
    "n2 = int(0.9 * len(words))\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])\n",
    "Xte, Yte = build_dataset(words[n2:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.randn((27,2)) # letters to embeddings\n",
    "W1 = torch.randn((6, 100))\n",
    "b1 = torch.randn(100)\n",
    "W2 = torch.randn((100, 27))\n",
    "b2 = torch.randn(27)\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
